{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../resources/config.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir_when_not_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path) #also creates all intermediates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_loader(connection, dataset_folder: str = dataset_folder, dataset_info: list = dataset_info):\n",
    "    \"\"\"\n",
    "    This function loads all datasets from the landingzone into in-memory tables with the use of a duckdb connection\n",
    "    \"\"\"\n",
    "\n",
    "    for dataset in dataset_info:\n",
    "        file_path = f'{dataset_folder}/{dataset.dataset_name}/{dataset.dataset_name}.{dataset.file_format}'\n",
    "        logger.info(f'trying to open flat file at: {file_path}')\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        CREATE OR REPLACE TABLE {dataset.dataset_name} AS \n",
    "        SELECT * FROM '{file_path}'\n",
    "        \"\"\"\n",
    "        try:\n",
    "            connection.sql(query)\n",
    "            logger.info(f'Successfully read flat file at: {file_path} and created table: {dataset.dataset_name}')\n",
    "        except Exception as e:\n",
    "            logger.error(f'error while loading file at: {file_path}, with error: {e}')\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_stager(connection, medallion_zone: str, datasets: list, staging_format: str = staging_format):\n",
    "    \"\"\"\n",
    "    This function stages/saves in-memory tables in a folder\n",
    "    It checks if the folder/stage corresponds to one of the medallion architecture names (bronze, silver, gold)\n",
    "    \"\"\"\n",
    "\n",
    "    #avoid creation of files at paths we dont want.\n",
    "    if medallion_zone not in medallion_zones:\n",
    "        error_message = f\"\"\"The dataset_stager function was entered with medallion_zone={medallion_zone}, which in unsupported. \n",
    "        Supported zones are: {medallion_zones}\"\"\"\n",
    "        logger.error(error_message)\n",
    "        raise ValueError(error_message)\n",
    "\n",
    "    #Save in-memory tables\n",
    "    for dataset in datasets:\n",
    "        try:\n",
    "            partial_destination_path = f'{dataset_folder}/output/{medallion_zone}/'\n",
    "            full_destination_path = f'{dataset_folder}/output/{medallion_zone}/{dataset}.{staging_format}'\n",
    "            make_dir_when_not_exists(partial_destination_path) #When the dir does not exist, we have to make it\n",
    "\n",
    "            logger.info(f'trying to save table {dataset} as {staging_format} at {full_destination_path}')\n",
    "\n",
    "            query = f\"\"\"\n",
    "            COPY (SELECT * FROM {dataset}) TO '{full_destination_path}' (FORMAT {staging_format})\n",
    "            \"\"\"\n",
    "\n",
    "            connection.execute(query)\n",
    "            logger.info(f'dataset: {dataset} saved at: {full_destination_path}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f'error while staging dataset: {dataset} at: {full_destination_path}, with error: {e}')\n",
    "            raise\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_airbnb_for_silver(connection, table='airbnb'):\n",
    "    \"\"\"\n",
    "    This is a dedicated function to clean the rentals data.\n",
    "    It does a couple of specific things:\n",
    "    only keeping the zipcodes that are complete and follow the right format\n",
    "    Casting all column types to the right type\n",
    "    \"\"\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE airbnb_cleaned AS \n",
    "    SELECT zipcode\n",
    "    ,latitude\n",
    "    ,longitude\n",
    "    ,room_type\n",
    "    ,CAST(accommodates as int) AS accommodates\n",
    "    ,CAST(bedrooms as int) AS bedrooms\n",
    "    ,CAST(price as int) AS price\n",
    "    ,CAST(review_scores_value as int) AS review_scores_value\n",
    "    FROM {table}\n",
    "    WHERE zipcode ~ '^[0-9]{{4}} [A-Z]{{2}}$'\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(f'trying to clean airbnb data')\n",
    "    try:\n",
    "        connection.sql(query)\n",
    "        logger.info('succesfully cleaned the airbnb data')\n",
    "    except Exception as e:\n",
    "        logger.error(f'Error while cleaning the airbnb data: {e}')\n",
    "        raise\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rentals_for_silver(connection, table='rentals'):\n",
    "    \"\"\"\n",
    "    This is a dedicated function to clean the rentals data.\n",
    "    It does a couple of specific things:\n",
    "    only keeping the numbers in the rent column\n",
    "    adding a space in the postalcode so it has the right format.\n",
    "    only keeping rows that make sense (for rent and postalCode)\n",
    "    dropping all other rows\n",
    "    renaming rent and postalCode to price and zipcode to match airbnb data\n",
    "    \"\"\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE rentals_cleaned AS\n",
    "    SELECT \n",
    "    substring(postalCode FROM 1 FOR 4) || ' ' || substring(postalCode FROM 5) AS zipcode\n",
    "    ,CAST(regexp_replace(rent, '[^0-9]', '', 'g') as int) AS price\n",
    "    FROM {table}\n",
    "    WHERE 1=1\n",
    "    AND substring(postalCode FROM 1 FOR 4) || ' ' || substring(postalCode FROM 5) ~ '^[0-9]{{4}} [A-Z]{{2}}$'\n",
    "    AND regexp_replace(rent, '[^0-9]', '', 'g') <> ''\n",
    "    \"\"\"\n",
    "    logger.info(f'trying to clean rental data')\n",
    "    \n",
    "    try:\n",
    "        connection.sql(query)\n",
    "        logger.info('succesfully cleaned the rental data')\n",
    "    except Exception as e:\n",
    "        logger.error(f'Error while cleaning the rental data: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(connection):\n",
    "    \"\"\"\n",
    "    This is a dedicated function to combine/aggregate the rentals and airbnb data.\n",
    "    We do this by taking the average of the rental price and airbnb price seperated as they cant be compared\n",
    "    We also add a count, which show how many observations in each zipcode are making up the total average.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    query = \"\"\"\n",
    "    CREATE OR REPLACE TABLE aggregate_data AS\n",
    "    SELECT\n",
    "    zipcode\n",
    "    ,ROUND(AVG(price_airbnb), 2) AS average_price_airbnb\n",
    "    ,ROUND(AVG(price_rentals), 2) AS average_price_rental\n",
    "    ,SUM(airbnb_flag) AS airbnb_count\n",
    "    ,SUM(rental_flag) AS rental_count\n",
    "    FROM\n",
    "    (\n",
    "        SELECT \n",
    "        zipcode\n",
    "        ,price AS price_airbnb \n",
    "        ,NULL AS price_rentals\n",
    "        ,1 AS airbnb_flag\n",
    "        ,0 AS rental_flag\n",
    "        FROM \n",
    "        airbnb_cleaned\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT\n",
    "        zipcode\n",
    "        ,NULL AS price_airbnb\n",
    "        ,price AS price_rentals\n",
    "        ,0 AS airbnb_flag\n",
    "        ,1 AS rental_flag\n",
    "        FROM \n",
    "        rentals_cleaned\n",
    "    ) AS T\n",
    "    GROUP BY zipcode\n",
    "    ORDER BY average_price_rental, average_price_airbnb asc\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(f'trying to aggregate the rental and airbnb datasets')\n",
    "    try:\n",
    "        connection.sql(query)\n",
    "        logger.info('succesfully aggregated the rental and airbnb datasets')\n",
    "    except Exception as e:\n",
    "        logger.error(f'Error while cleaning the rental data: {e}')\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
